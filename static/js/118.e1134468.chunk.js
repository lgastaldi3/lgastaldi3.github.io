"use strict";(self.webpackChunkreact_tailwindcss_portfolio=self.webpackChunkreact_tailwindcss_portfolio||[]).push([[118],{3824:(e,t,a)=>{a.r(t),a.d(t,{default:()=>f});var r=a(3216),i=a(5043);a.p,a.p;var n=a(2388);a.p,a.p,a.p;const s=a.p+"static/media/solv-page-project.6e484a0be62de5fa0ea9.jpg";var o=a(8254),l=a(579);const d={solv:{ProjectHeader:{title:"Solv AI-Enabled Tutor",publishDate:"May 2023 \u2013 July 2024",tags:"Web App, AI, React, Flask, OpenAI, Azure, Canvas API, Figma, PostHog"},ProjectImages:[{id:1,title:"Solv AI dashboard screenshot",img:s},{id:2,title:"Solv AI Canvas integration screenshot",img:s},{id:3,title:"Solv AI analytics panel screenshot",img:s}],ProjectInfo:{ClientHeading:"About Involvement",CompanyInfo:[{id:1,title:"Solv AI Technologies",details:"Independent Startup"},{id:2,title:"Role",details:"Chief Software Engineer \u2013 Led backend development and directed technical roadmap"}],ObjectivesHeading:"Objective",ObjectivesDetails:"Solv AI Technologies is an AI-powered web application designed to transform how students engage with their course content on Canvas. Developed as part of an independent startup, the project was shaped by over 300 customer discovery and research interviews to ensure a user-centered solution for contextual, accurate answers from personal course materials.",Technologies:[{title:"Tools & Technologies",techs:["React","Python Flask","OpenAI API","Azure","Canvas API","Figma","PostHog"]}],ProjectDetailsHeading:"Key Features & Challenges",ProjectDetails:[{id:1,details:"At its peak, Solv AI Technologies supported up to 500 concurrent users, demonstrating robust scalability and real-world demand. The platform offers seamless Canvas integration for each user, providing access to personal course files and enabling natural language question answering through retrieval-augmented generation. The system supports follow-up questions that retain prior file context, allowing for deeper academic conversations. References in answers include direct links to relevant pages within Canvas content, and the AI tutoring interface mimics real-time dialogue for an engaging user experience."},{id:2,details:"The platform features PostHog-powered usage analytics and an admin panel, as well as custom authentication with elevated permissions for internal users. A major challenge was ensuring full compliance with Canvas API terms and handling diverse file formats, which was addressed by building custom pipelines for parsing PowerPoints, PDFs, DOCX files, and even video content. Dynamic content linking was achieved by creating a robust system to map answers to exact source locations in course materials, enhancing user trust and usability."},{id:3,details:"Prompt engineering was a key focus: Solv leverages RAG to preprocess relevant content into narrow, highly contextual prompts, minimizing issues with OpenAI's context window limits and ensuring efficient, accurate responses."}],SocialSharingHeading:"Share This",SocialSharing:[{id:1,name:"Twitter",icon:(0,l.jsx)(o.TC4,{}),url:"https://twitter.com/realstoman"},{id:2,name:"Instagram",icon:(0,l.jsx)(o.eCe,{}),url:"https://instagram.com/realstoman"},{id:4,name:"LinkedIn",icon:(0,l.jsx)(o.Wjy,{}),url:"https://linkedin.com/lgastaldi3/"}]},RelatedProject:{title:"Related Projects",Projects:[]}},gpt2:{ProjectHeader:{title:"Custom GPT2 Recreation",publishDate:"March 2025 \u2013 May 2025",tags:"Machine Learning, NLP, AI Research, PyTorch, Python, Google Colab"},ProjectImages:[{id:1,title:"GPT-2 model architecture diagram",img:n},{id:2,title:"Training progress visualization",img:n},{id:3,title:"Generated text samples",img:n}],ProjectInfo:{ClientHeading:"About Project",CompanyInfo:[{id:1,title:"Project Type",details:"Independent / Personal Research"},{id:2,title:"Role",details:"Sole developer \u2013 implemented dataset preprocessing, model architecture, training loop, and evaluation"}],ObjectivesHeading:"Objective",ObjectivesDetails:"Custom GPT2 Recreation is a fully custom-built natural language generation model designed to mimic the architecture and behavior of GPT-2 at a simplified scale. Trained on a curated dataset of movie quotes, this project was an exploration of deep learning architecture design, constrained learning, and the limits of language generation under strict resource constraints.",Technologies:[{title:"Tools & Technologies",techs:["PyTorch","Python","Google Colab"]}],ProjectDetailsHeading:"Key Features & Challenges",ProjectDetails:[{id:1,details:"Built in PyTorch, the project began with preprocessing the MovieQuote dataset \u2014 including cleaning punctuation and tokenizing the data at both the word and letter level. Letter-level inputs were further processed using convolutional layers (3\u20135 wide) to extract local features. The model itself followed an encoder-decoder architecture, incorporating transformer-style single-head attention and beam search to improve output quality during decoding."},{id:2,details:"Despite being trained on just 10MB of data for 10 epochs using a single Colab GPU, the model was able to generate cohesive English text resembling conversational movie dialogue. This result was notable given the severe constraints on data size, compute, and time, and required careful iteration to distinguish genuine model improvements from noisy or incoherent outputs."},{id:3,details:"One of the primary challenges in building Custom GPT2 Recreation was operating within significant resource limitations. Developing the model on Google Colab meant access to only a single GPU, which constrained the dataset size and required careful management of batch sizes and training iterations to make meaningful progress. With just 10MB of training data available, the model was highly susceptible to overfitting and noise, making it difficult to generalize or produce fluent text reliably. To mitigate this, letter-based tokenization paired with convolutional layers was used to improve representation efficiency. Another key difficulty was evaluating output quality \u2014 the model\u2019s responses often hovered between plausible and incoherent, and without large-scale benchmarks, progress was assessed manually through qualitative analysis and tuning. These constraints demanded a highly iterative and resource-aware development process."}],SocialSharingHeading:"Share This",SocialSharing:[{id:1,name:"LinkedIn",icon:(0,l.jsx)(o.Wjy,{}),url:"https://linkedin.com/lgastaldi3/"}]},RelatedProject:{title:"Related Projects",Projects:[]}}},c=(0,i.createContext)(),g=e=>{let{children:t,projectSlug:a="solv"}=e;const[r,n]=(0,i.useState)(d[a]||d.solv);return(0,l.jsx)(c.Provider,{value:{singleProjectData:r,setSingleProjectData:n,setCurrentProject:e=>{n(d[e]||d.solv)}},children:t})},m=c,h=()=>{const{singleProjectData:e}=(0,i.useContext)(m);return(0,l.jsx)("div",{className:"grid grid-cols-1 sm:grid-cols-3 sm:gap-10 mt-12",children:e.ProjectImages.map((e=>(0,l.jsx)("div",{className:"mb-10 sm:mb-0",children:(0,l.jsx)("img",{src:e.img,className:"rounded-xl cursor-pointer shadow-lg sm:shadow-none",alt:e.title},e.id)},e.id)))})},u=()=>{const{singleProjectData:e}=(0,i.useContext)(m);return(0,l.jsxs)("div",{children:[(0,l.jsx)("p",{className:"font-general-medium text-left text-3xl sm:text-4xl font-bold text-primary-dark dark:text-primary-light mt-14 sm:mt-20 mb-7",children:e.ProjectHeader.title}),(0,l.jsxs)("div",{className:"flex",children:[(0,l.jsxs)("div",{className:"flex items-center mr-10",children:[(0,l.jsx)(o.Ohp,{className:"text-lg text-ternary-dark dark:text-ternary-light"}),(0,l.jsx)("span",{className:"font-general-regular ml-2 leading-none text-primary-dark dark:text-primary-light",children:e.ProjectHeader.publishDate})]}),(0,l.jsxs)("div",{className:"flex items-center",children:[(0,l.jsx)(o.cnX,{className:"text-lg text-ternary-dark dark:text-ternary-light"}),(0,l.jsx)("span",{className:"font-general-regular ml-2 leading-none text-primary-dark dark:text-primary-light",children:e.ProjectHeader.tags})]})]})]})},p=()=>{const{singleProjectData:e}=(0,i.useContext)(m);return(0,l.jsxs)("div",{className:"block sm:flex gap-0 sm:gap-10 mt-14",children:[(0,l.jsxs)("div",{className:"w-full sm:w-1/3 text-left",children:[(0,l.jsxs)("div",{className:"mb-7",children:[(0,l.jsx)("p",{className:"font-general-regular text-2xl font-semibold text-secondary-dark dark:text-secondary-light mb-2",children:e.ProjectInfo.ClientHeading}),(0,l.jsx)("ul",{className:"leading-loose",children:e.ProjectInfo.CompanyInfo.map((e=>(0,l.jsxs)("li",{className:"font-general-regular text-ternary-dark dark:text-ternary-light",children:[(0,l.jsxs)("span",{children:[e.title,": "]}),(0,l.jsx)("a",{href:"https://stoman.me",className:"Website"===e.title||"Phone"===e.title?"hover:underline hover:text-yellow-500 dark:hover:text-yellow-400 cursor-pointer duration-300":"","aria-label":"Project Website and Phone",children:e.details})]},e.id)))})]}),(0,l.jsxs)("div",{className:"mb-7",children:[(0,l.jsx)("p",{className:"font-general-regular text-2xl font-semibold text-ternary-dark dark:text-ternary-light mb-2",children:e.ProjectInfo.ObjectivesHeading}),(0,l.jsx)("p",{className:"font-general-regular text-primary-dark dark:text-ternary-light",children:e.ProjectInfo.ObjectivesDetails})]}),(0,l.jsxs)("div",{className:"mb-7",children:[(0,l.jsx)("p",{className:"font-general-regular text-2xl font-semibold text-ternary-dark dark:text-ternary-light mb-2",children:e.ProjectInfo.Technologies[0].title}),(0,l.jsx)("p",{className:"font-general-regular text-primary-dark dark:text-ternary-light",children:e.ProjectInfo.Technologies[0].techs.join(", ")})]}),(0,l.jsxs)("div",{children:[(0,l.jsx)("p",{className:"font-general-regular text-2xl font-semibold text-ternary-dark dark:text-ternary-light mb-2",children:e.ProjectInfo.SocialSharingHeading}),(0,l.jsx)("div",{className:"flex items-center gap-3 mt-5",children:e.ProjectInfo.SocialSharing.map((e=>(0,l.jsx)("a",{href:e.url,target:"__blank","aria-label":"Share Project",className:"bg-ternary-light dark:bg-ternary-dark text-gray-400 hover:text-primary-dark dark:hover:text-primary-light p-2 rounded-lg shadow-sm duration-500",children:(0,l.jsx)("span",{className:"text-lg lg:text-2xl",children:e.icon})},e.id)))})]})]}),(0,l.jsxs)("div",{className:"w-full sm:w-2/3 text-left mt-10 sm:mt-0",children:[(0,l.jsx)("p",{className:"font-general-regular text-primary-dark dark:text-primary-light text-2xl font-bold mb-7",children:e.ProjectInfo.ProjectDetailsHeading}),e.ProjectInfo.ProjectDetails.map((e=>(0,l.jsx)("p",{className:"font-general-regular mb-5 text-lg text-ternary-dark dark:text-ternary-light",children:e.details},e.id)))]})]})},x=()=>{const{singleProjectData:e}=(0,i.useContext)(m);return(0,l.jsxs)("div",{className:"mt-10 pt-10 sm:pt-14 sm:mt-20 border-t-2 border-primary-light dark:border-secondary-dark",children:[(0,l.jsx)("p",{className:"font-general-regular text-primary-dark dark:text-primary-light text-3xl font-bold mb-10 sm:mb-14 text-left",children:e.RelatedProject.title}),(0,l.jsx)("div",{className:"grid grid-cols-1 sm:grid-cols-4 gap-10",children:e.RelatedProject.Projects.map((e=>(0,l.jsx)("img",{src:e.img,className:"rounded-xl cursor-pointer",alt:e.title},e.id)))})]})};var j=a(1605);const f=()=>{const{projectSlug:e}=(0,r.g)();return(0,l.jsx)(j.P.div,{initial:{opacity:0},animate:{opacity:1,delay:1},transition:{ease:"easeInOut",duration:.6,delay:.15},className:"container mx-auto mt-5 sm:mt-10",children:(0,l.jsxs)(g,{projectSlug:e,children:[(0,l.jsx)(u,{}),(0,l.jsx)(h,{}),(0,l.jsx)(p,{}),(0,l.jsx)(x,{})]})})}},2388:(e,t,a)=>{e.exports=a.p+"static/media/mobile-project-2.a5aae7867760d0c29dd2.jpg"}}]);
//# sourceMappingURL=118.e1134468.chunk.js.map